{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Sentiment Analysis_Kaggle_Data",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMR/UbebEM9RoGkzf//KqZt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Puru-Gupta/IMDB_Sentiment_Analysis_Bidirectional_LSTM/blob/main/IMDB_Sentiment_Analysis_Kaggle_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCTgpVtz3UDL"
      },
      "source": [
        "##**IMDB dataset** \n",
        "**Having 50K movie reviews for natural language processing or Text analytics.**\n",
        "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. *We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms*.\n",
        "For more dataset information, please go through the following link,\n",
        "More_detail: [http://ai.stanford.edu/~amaas/data/sentiment/]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFcFMYTd4X5y"
      },
      "source": [
        "##**We'll be building the following:**<br>\n",
        "**Model 1: Naive Bayes (baseline Model)**<br>\n",
        "**Model 2: Feed-forward neural network (dense model)**<br>\n",
        "**Model 3: LSTM model**<br>\n",
        "**Model 3: GRU model**<br>\n",
        "**Model 4: TensorFlow Hub Pretrained Feature Extractor** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYQJAzY_e_yv",
        "outputId": "76667660-1ed6-4a14-b29d-937668691d50"
      },
      "source": [
        "#Fro Importing data from kaggle \n",
        "#Install the Kaggle first \n",
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "CFgtoCg6kGxN",
        "outputId": "c8f52b4b-0a45-4a89-dc33-d1998dd6bc20"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df817249-cfe8-4c73-a624-e7b65e79a18b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df817249-cfe8-4c73-a624-e7b65e79a18b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"purushottamgupta\",\"key\":\"dbaa764b15959296b10e816f5c6905ce\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMUo2EObkG6x",
        "outputId": "0a620a22-15e9-4052-f2f6-c6e5af86c75e"
      },
      "source": [
        "#Now we rae going to craete kaggle directory\n",
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsAmvXBskHEs"
      },
      "source": [
        "# Now se will copy the json file to folder that we have created\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aavFN-GzkHSn",
        "outputId": "1640a736-0d66-4405-9b51-4b60d1baa342"
      },
      "source": [
        "#Now we need permision to get json file act\n",
        "! chmod 600 ~/.kaggle4/kaggle.json\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/root/.kaggle4/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9H9i2RZkHW6",
        "outputId": "e83b52c3-3013-4b4f-9009-f401ebe10746"
      },
      "source": [
        "##Kaggle API Command for getting Data directly from Kaggle\n",
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to /content\n",
            " 66% 17.0M/25.7M [00:00<00:00, 70.6MB/s]\n",
            "100% 25.7M/25.7M [00:00<00:00, 85.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpbTV2n4kHaV",
        "outputId": "707563a2-e0ca-4697-c7e2-3a0f6fec2fde"
      },
      "source": [
        "import zipfile\n",
        "! unzip /content/imdb-dataset-of-50k-movie-reviews.zip\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68FhLxkM6Osr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "WR5A7mEjkbiQ",
        "outputId": "7e24b91f-5ecb-4f9b-ba6b-5d30be029959"
      },
      "source": [
        "data_reviews = pd.read_csv(\"/content/IMDB Dataset.csv\")\n",
        "data_reviews.shape\n",
        "data_reviews"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDb8d8iN6W-x",
        "outputId": "07c51080-3630-465e-eb39-20b80823fb79"
      },
      "source": [
        "import random\n",
        "data_list = data_reviews[\"review\"]\n",
        "sample_data = random.choices(data_list, k=1)\n",
        "print(sample_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['One hour, eight minutes and twelve seconds into this flick and I decided it was pretty lame. That was right after Hopalong (Chris Lybbert) drops on his horse from a tree to rejoin the good guy posse. I was pretty mystified by the whole Hopalong Cassidy/Great Bar 20 gimmick which didn\\'t translate into anything at all. Obviously, the name Coppola in the credits couldn\\'t do anything to guarantee success here, even with more than one listed.<br /><br />If you make it to the end of the film, you\\'ll probably wind up asking yourself the same questions I did. What exactly was the hook with the gloves? What\\'s up with the rodeo scenario? Who was The Stranger supposed to represent? Why did they make this film? <br /><br />I could probably go on but my energy\\'s been drained. Look, there\\'s already a Western called \"The Gunfighter\" from 1950 with a guy named Gregory Peck as the title character. Watching it will make you feel as good as watching this one makes you feel bad. That one I can recommend.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASlln4Qx_pLZ",
        "outputId": "42d12f76-01ea-40e9-9bf3-ab5d7d85beb0"
      },
      "source": [
        "data_reviews.sentiment.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    25000\n",
              "positive    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "yL_YyIUn__hC",
        "outputId": "aaa71d74-48fb-4183-a869-fb56a66f57bf"
      },
      "source": [
        "#Suffle data\n",
        "suffle_reviews = data_reviews.sample(frac = 1, random_state=42)\n",
        "suffle_reviews.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33553</th>\n",
              "      <td>I really liked this Summerslam due to the look...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9427</th>\n",
              "      <td>Not many television shows appeal to quite as m...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>The film quickly gets to a major chase scene w...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12447</th>\n",
              "      <td>Jane Austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39489</th>\n",
              "      <td>Expectations were somewhat high for me when I ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "33553  I really liked this Summerslam due to the look...  positive\n",
              "9427   Not many television shows appeal to quite as m...  positive\n",
              "199    The film quickly gets to a major chase scene w...  negative\n",
              "12447  Jane Austen would definitely approve of this o...  positive\n",
              "39489  Expectations were somewhat high for me when I ...  negative"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBaUtJTMA06i",
        "outputId": "3ff9b680-73db-483a-c173-3febafa75dcf"
      },
      "source": [
        "import random\n",
        "random_index = random.randint(0, len(data_reviews)-5)\n",
        "for row in suffle_reviews[[\"review\", \"sentiment\"]][random_index:random_index+1].itertuples():\n",
        "  _, review, sentiment = row\n",
        "  print(suffle_reviews['sentiment'])\n",
        "  print(\"\\n\")\n",
        "  print(suffle_reviews['review'])\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSJ8kSozkHdX"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV10HbECFt0-"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "suffle_reviews[\"sentiment\"] = LabelEncoder().fit_transform(suffle_reviews[\"sentiment\"])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuQK-ZZZkHhZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(suffle_reviews[\"review\"].to_numpy(),\n",
        "                                                                            suffle_reviews[\"sentiment\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA8cr7KvkHk9",
        "outputId": "912a1860-655c-4706-9a67-a54c2ddeb675"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 45000, 5000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPL9nEXikHo7",
        "outputId": "ae5f43a4-09db-42da-e35e-d55a94a46bd1"
      },
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['Prot (Kevin Spacey) is a mental hospital patient who claims to be native to a distant planet called K-PAX. His psychiatrist, Dr. Mark Powell (Jeff Bridges) tries to help him, all the while trying to understand Prot and find out if he is really from K-PAX.<br /><br />This movie doesn\\'t really fall into any particular genre. One big part of K-PAX is drama/ science-fiction, another part fantasy, plus, add to that a dash of comedy and you begin to get what K-PAX is all about. The story (as you see above) isn\\'t too complicated or deep, but it still offers some good twists and turns of the plot that may still surprise you as they did me. No special effects or graphics accompany this movie, and there\\'s no need to have them, the music in the film is great however. A techno soundtrack along with a terrific piano piece makes K-PAX sound sci-fi and makes certain scenes intriguing.<br /><br />Kevin Spacey is the heart of the movie and plays a very convincing alien (Prot) from the planet K-PAX, emotional with great facial expressions, Spacey does a fine job in the lead role. Jeff Bridges is Dr. Powell, that aids and attempts to understand Prot. Bridges is also excellent in his part. Bridges and Spacey fit together very well and they should, after all, they\\'ve both had a lot of experience. The wife of Dr. Powell is Rachel Powell, played by Mary McCormack. McCormack plays her part well, showing the frustration from having her husband gone and so dedicated to his patient. Alfe Woodard plays Dr. Powell\\'s coworker Claudia Villars, we don\\'t really see Claudia too much, but overall she puts in an alright performance.<br /><br />K-PAX is rated PG-13 for \"a sequence of violent images, and brief language and sensuality\", and that covers it. As far as \"violent images\" go, we don\\'t see too much. A few people that have quite a bit of blood on them, but that\\'s all. Language is as follows: 1 \"f\" word (wow, only one!), 11 \"s\" words, and a few uses of the Lord\\'s name in vain. Not too bad really. The \"sensuality\" part is just from when Prot explains to Dr. Powell how reproduction works on K-PAX, nothing terrible, just something about it feels like \"having your nuts in a vice.\" Not too bad on the content level for a PG-13 movie, it could have been a lot worse.<br /><br />In conclusion, K-PAX is not a bad movie. It won\\'t stun you, but it is enjoyable and kind of fun to watch. It has some funny parts, sad parts, really sad parts, and, well you know what I mean. It\\'s a story of a mental hospital patient, what do you expect? All in all a good rent for those of you looking for a good drama that you can kick back and relax to, K-PAX is a well done movie.<br /><br />Bonus! If you\\'ve seen this movie already, like it, and are thinking about getting the DVD, I would highly recommend it. It has loads of extras to look through, and even an alternate ending and deleted scenes. 8/10',\n",
              "        'Immediately after renting and watching this movie several years ago, a friend and I decided that it defined the absolute zero on the movie scale. There was nothing about the movie that could have been done worse than it was. To this day we still rate movies, even very bad ones, by how much better than \"The Lonely Lady\" they are.<br /><br />A long time ago I saw an interview with Eleanor Perry, who wrote the screenplays for, among other things, \"Last Summer\" and \"Diary of a Mad Housewife,\" and she related that she had been asked to write a screenplay for the Harold Robbins\\' book \"The Lonely Lady.\" She said that she sent in a treatment and it was rejected because they didn\\'t think she understood the difficulties of a female screenwriter in Hollywood. She then said \"I think they got someone else to write it.\" The interview was filmed before the movie was released. She died in 1981, and I bet the first thing she did on arrival in heaven was personally thank God for saving her from involvement in the result.',\n",
              "        \"A surprisingly good documentary. My surprise was mainly due to the fact that I was confused by the title. I assumed this was about the influence of the drug culture on film making but no it is a much more far reaching and intelligent film than could have been expected. Demme has done a great job in encapsulating the period from the late 60s to the late 70s. From, 'Easy Rider' and the collapse of studio influence, through all those introspective 'real life' movies, where brilliant young directors tried to express themselves politically, sexually and artistically, through to the beginnings of the blockbuster and the return of the reigns to the money men and their studios. As someone who saw the 'real life' movies of Britain and the rest of Europe through the sixties and then the revolutionary US films of the 70s and is sad that the sequel to the sequel is so much the order of the day, this was a most fascinating film. The interview clips are measured (thanks to DVD the full interviews are available as extras!) and the film clips well considered. Also, as someone who has only just caught up with, 'Joe', I am impressed that this important little film gets its well deserved entry here.\",\n",
              "        'I first saw \"The Knowledge\" during a Thames Television marathon on one of the local independent stations in Los Angeles back when it was new. I enjoyed it very much along with danger UXB.<br /><br />That a movie I saw once over twenty year ago should stick so well in my memory is a testament to it\\'s originality and the quality of the performances by the cast.<br /><br />I looked for a DVD copy here in the U.S.A. And found none. I finally gambled and bought a UK DVD off Ebay and was delighted to find that it has no Region Code. So those of us that would like to see this little gem can get a copy.',\n",
              "        \"Rivalry between brothers leads to main story line. Navy Commander Chuck Prescott(Marshall Thompson)has developed the Y12 aircraft to test how far man can go up in the atmosphere. His brother, Lt. Dan Prescott(Bill Edwards), seems to be the best test pilot around and is chosen to go up in the Y12. Dan of course has a problem with taking orders and is also an over confident dare devil. <br /><br />On Dan's second flight, he hits over the 300 miles up comfort zone and his craft passes through a meteor dust storm. Returning to earth, Dan becomes a monster that resembles 200 pounds of bad asphalt. He also has a demanding craving for blood, whether it be from farm animals or fellow human beings.<br /><br />Short runtime of an hour and seventeen minutes; black & white with near stoic acting...typical of low budget sci-fi.<br /><br />Rounding out the cast is Marla Landi, Robert Ayers and Carl Jaffe. Noteworthy trivia: about two months after this film was released; the Russians put the real first man in space.\",\n",
              "        'This has become one of my favorite movies and certainly one of the best westerns I have ever seen. Having a soft spot for the genre (westerns are \\x96 or were, since they are no longer made very often \\x96 morality plays that too often have been denigrated by critics with intellectual pretensions), I purchased the DVD, sight unseen, because I had read enough about William S. Hart\\'s work (much of which he wrote and directed) to pique my interest and thought I should have at least one of his films in my video collection.<br /><br />I must admit that I approached the actual viewing with some trepidation. My previous experiences with silent cinema \"classics\" had left me feeling let down. Chaney\\'s The Phantom of the Opera, Griffith\\'s Birth of a Nation and Fairbanks\\' The Mark of Zorro were fine, but not nearly as good as their reputations would lead one to expect. They were either too long, or too theatrical, or both. <br /><br />The Toll Gate, however, emerged as a pleasant surprise.<br /><br />It is a story told in a simple and straightforward manner. Black Deering (played by Hart), leader of a notoriously successful outlaw gang, thinks the time has come for group to disband, before its luck runs out. He is, however, opposed by his chief lieutenant, Jordan, who goads them all into one last holdup by promising great wealth but leads them into a trap in which he is complicit. Everyone is killed except Deering, who is taken prisoner. When his captors recognize him as the man who once saved a number of soldiers and settlers by warning an outpost of an impending Indian attack, they allow him to escape. Free, he tries to find honest work but is snubbed and ridiculed and ultimately must rob again to survive. Soon, he is pursued not only by the sheriff\\'s posse but also by Jordan (now prospering from the reward money he has collected) and his henchmen. His flight leads him to a remote cabin inhabited by a single mother and her little son. After some initial misgivings, they take him into their hearts. Deering sees a chance for a new life but, with the posse and Jordan closing in, realizes that this may not be possible. <br /><br />Hart was the first great western star and the first to inject realism into the genre. As one of the pioneers of movie-making, he created many of the characters and situations that have become cliché in westerns for more than ninety years. What keeps his movies interesting, however, was his ability to go beyond the cliché (perhaps his imitators did not go far enough) so that the material appears fresh and innovative, even now. Three such instances in The Toll Gate illustrate this: <br /><br />1) In one scene, his character shoots into a crowd in an attempt to kill Jordan, and kills a bystander instead. A subsequent close-up shows that he is clearly frustrated. The frustration, however, comes not from the fact that he has gunned down a man who had hitherto caused him no harm but that he missed his intended target. <br /><br />2) In another, as he flees from the posse, his \"borrowed\" horse steps into a gopher hole and breaks a leg. Hart pulls out his gun to put the animal out of its misery but, before pulling the trigger, gives his head a sad, loving pat, as if to say farewell to an old friend. <br /><br />3) And finally, after he has strangled Jordan and thrown his body over a cliff, he returns to retrieve his guns and spots his adversary\\'s pistol lying on the ground nearby. He steps forward and gives it a swift kick before mounting his horse. It is a simple gesture but it underscores the deep loathing he feels for the man who betrayed him and his comrades. <br /><br />And I love the title, The Toll Gate. It is allegorical in its implication that a man cannot begin a new life until he has paid for the sins of his old one. Deering\\'s payment comes in the form of sacrifice. Today\\'s more sophisticated audiences may not buy into that sentiment entirely but it can still work on you if you let it.<br /><br />Viewers who like their videos in pristine condition will undoubtedly object to the DVD\\'s picture quality, especially the badly deteriorated final reel. I don\\'t mind at all. That a copy of this 1920 movie even exists at all is a miracle since prints of so many other silent movies have been lost. If you bear that in mind and look upon the film as a piece of history, its visual flaws are not that difficult to accept. <br /><br />William S. Hart was born in 1870 in New York but grew up in the Minnesota and Wisconsin where he learned to speak Sioux and Indian sign language. He counted Wyatt Earp and Bat Masterson among his friends and collected Remington paintings, so his knowledge of the West was first-hand. If his vision seems overly romanticized by today\\'s standards, it is nevertheless rooted far closer to reality than the spaghetti westerns of the \\'60s and \\'70s and the revisionist works that followed. Both the star and his films are overdue for re-evaluation.',\n",
              "        'The whole movie was done half-assed. It could have been a much better movie but, that would have required a re-write and different actors. Compared to \"Traffic\" this was a wreck. I am just glad I didn\\'t have to pay for it.<br /><br />Spoiler:<br /><br />What was the point of having crooked cops getting arrested? To share the guilt of drug dealers and make them feel better? Pu-leaze! The parents were scum, driven by greed, and didn\\'t even consider the harm they were doing; as pointed out by Ice-T. <br /><br />2 out of 10',\n",
              "        'When I was a kid I watched this many times over, and I remember whistling the \"Happy Cat\" song quite often. All the songs are great, and actually memorable, unlike many children\\'s musicals, where the songs are just stuck in for no real reason. The scenes and costumes are lavish, and the acting is very well-done, which isn\\'t surprising, considering the cast. Christopher Walken is very catlike, and doesn\\'t need stupid make-up, or a cat costume for the viewer to believe he\\'s a cat transformed to a human. And Jason Connery\\'s so cute, as the shy and awkward miller\\'s son, Corin, who falls in love with beautiful and the bold Princess Vera. This is a really fun, enjoyable, feature-length movie, where unlike most fairytales, the characters are given personalities. Some of my favourite parts are when Puss makes Corin pretend he\\'s drowning; at the ball when everybody starts dancing a country dance, as it\\'s \"all the rage abroad\"; when Walken is in the kitchen, dancing on the table (he\\'s a pretty good dancer, too!); and when Vera tells Corin all the things she used to do when she was young, like pretending she was a miller\\'s daughter. I\\'d recommend this film to children and parents alike, who love magic and fairytales. And it actually IS a movie you can watch together, as it won\\'t drive adults up the wall.',\n",
              "        'Samuel Fuller\\'s Pickup on South Street is anomalous: A \"Red Scare\" movie devoid of hysteria, in which the Communist threat is nothing more than the McGuffin that ignites the plot. Pickpocket Richard Widmark relieves loose woman Jean Peters of her wallet containing a strip of microfilm; unbeknownst to either of them, it harbors secrets vital to the Cold War. Peters, as it happens, was under surveillance by FBI agents who are as nonplussed by the theft as the man who\\'s running her, cowardly comsymp Richard Kiley. In trying to retrieve the precious film, both sides enlist the help of Thelma Ritter, a streetwise old jane who\\'s always on the earie and willing to sell what she hears.<br /><br />Fuller draws from an opulent palette of tempos and tonalities in telling the story, which becomes a race against the clock of escalating brutality. From the subways to the waterfront, his midsummer Manhattan takes on a sweaty sheen that\\'s almost pungent. The love scenes between Peters and Widmark become an unstable mixture of the tumultuous and the tender, and they\\'re scored to \"Again,\" a song introduced by Ida Lupino in Road House, also starring Widmark. The pace slackens for Ritter\\'s beautifully written and played death scene -- among the most poignant vignettes in all noir, and a kind of mirage-oasis in a film parched of sentimentality. This is writer/director Fuller\\'s only work in the strictest confines of the noir cycle; his later explorations of American pathology (The Crimson Kimono, The Naked Kiss, Underworld U.S.A.) never resulted in a synthesis as satisfying as Pickup on South Street.',\n",
              "        '\"Masters of Horror\" has proved itself a poor arena for \\'message episodes,\\' and while a definite case can be made for Joe Dante\\'s \\'Screwfly Solution\\' (one of the best episodes of the series, period), most efforts to do so have come across as anvil-heavy and unimpressive (nothing defuses horror more than a soapbox). And \\'Pro-Life\\' simply fuses reactionary viewpoints with ultra-violence; young Angelique (Caitlin Wachs), seen running through the woods, is nearly hit by 2 doctors (Mark Feuerstein and Emmanuelle Vaugier) who just happen to be driving in to work at the local (and isolated) abortion clinic. Angelique\\'s father, Dwayne (Ron Perlman), is a stone-cold, far-right holy roller who will do anything to prevent his daughter from getting an abortion. If for nothing else, \\'Pro-Life\\' accumulated some buzz for its controversial issue, but John Carpenter treats this whole venture with startling indifference--he seems even less interested in making a movie than the script itself (which is admittedly poor); the slow pacing builds no tension, and simply brings the already ambling plot to a crawl. Even when Dwayne and his sons storm the clinic, guns blazing, it is a stunning non-event; later, when a doctor is tortured with a \\'male abortion,\\' the scene comes off as gratuitous and unnecessary--an effort to pad out the underwritten film. The poor performances (Perlman is sadly wasted here) become an outgrowth of the script, and Carpenter\\'s direction feels exhausted, as if \\'Pro-Life\\' is the source of his next hot meal. By the time a spider-creature with a human head and a guy in a latex monster suit are prowling the hallways, you just have to wonder what the minds behind this mess were thinking...'],\n",
              "       dtype=object), array([1, 0, 1, 1, 0, 1, 0, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "Ak2fuTlBMqDj",
        "outputId": "71ea475a-ab17-4de1-ee25-2336e50d995b"
      },
      "source": [
        "train_sentences"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"A surprisingly good documentary. My surprise was mainly due to the fact that I was confused by the title. I assumed this was about the influence of the drug culture on film making but no it is a much more far reaching and intelligent film than could have been expected. Demme has done a great job in encapsulating the period from the late 60s to the late 70s. From, 'Easy Rider' and the collapse of studio influence, through all those introspective 'real life' movies, where brilliant young directors tried to express themselves politically, sexually and artistically, through to the beginnings of the blockbuster and the return of the reigns to the money men and their studios. As someone who saw the 'real life' movies of Britain and the rest of Europe through the sixties and then the revolutionary US films of the 70s and is sad that the sequel to the sequel is so much the order of the day, this was a most fascinating film. The interview clips are measured (thanks to DVD the full interviews are available as extras!) and the film clips well considered. Also, as someone who has only just caught up with, 'Joe', I am impressed that this important little film gets its well deserved entry here.\""
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAL7Ju2I7i6V",
        "outputId": "5dc75198-c64a-4d6f-a24f-2f86405137d8"
      },
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGPBBstsPQ3u"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6NwuZCtkH0Q"
      },
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 231 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    standardize='lower_and_strip_punctuation',\n",
        "                                    split='whitespace', ngrams=None, \n",
        "                                    output_mode='int',\n",
        "                                    pad_to_max_tokens=False,\n",
        "                                    output_sequence_length=max_length)\n",
        "            "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exTIntojkH4K"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuCCkNSckH7p",
        "outputId": "a2bd1e13-8193-4c37-f350-5aa3f839a401"
      },
      "source": [
        "#Example creating sample sequence and tokenize\n",
        "sample_sen= \" i love tesnorflow and its libraries\"\n",
        "text_vectorizer(sample_sen)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(231,), dtype=int64, numpy=\n",
              "array([ 10, 111,   1,   4,  30,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhGdbAXZkH_D",
        "outputId": "82561f4b-5cb2-4ed6-a7fa-2a264cc432a1"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "I first saw \"Breaking Glass\" when it was released in England in 1980..I loved it then and having just caught it in August 2005 on a Canadian station it still is great. The only thing I regret is I can't find the sound track or the DVD in the stores??...anyone care to shed some light or must I order it from some over priced internet company. But getting back to the film the music stands up to the test of time, Hazel/Kate had something to say about 80's Britain..actually it was the same decade I moved to Canada for some of the same reasons one being \"Thatcher\" and what she was doing to the country at the time. Please if you get the chance watch this movie you won't be sorry!      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 231), dtype=int64, numpy=\n",
              "array([[  10,   88,  204, 2453, 3009,   51,    9,   14,  626,    8, 1932,\n",
              "           8,    1,  427,    9,   91,    4,  255,   41, 1003,    9,    8,\n",
              "        6778, 3319,   21,    3, 2304, 1617,    9,  126,    7,   82,    2,\n",
              "          61,  148,   10, 2497,    7,   10,  172,  159,    2,  446, 1341,\n",
              "          40,    2,  269,    8,    2,    1,  458,    6, 3265,   47,  709,\n",
              "          40,  211,   10,  636,    9,   36,   47,  128,    1, 2899, 1084,\n",
              "          19,  374,  144,    6,    2,   20,    2,  208, 1334,   57,    6,\n",
              "           2, 2268,    5,   60,    1,   68,  138,    6,  129,   43,  810,\n",
              "           1,    9,   14,    2,  165, 2174,   10, 1613,    6, 3901,   17,\n",
              "          47,    5,    2,  165, 1011,   29,  107,    1,    4,   49,   59,\n",
              "          14,  390,    6,    2,  690,   31,    2,   60,  597,   44,   23,\n",
              "          76,    2,  575,  104,   11,   18,   23,  457,   27,  747,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXGO_V5ARiBy"
      },
      "source": [
        "count = []\n",
        "for x in range(len(suffle_reviews)):\n",
        "  lenght_words = len(suffle_reviews['review'][x])\n",
        "  count.append(lenght_words)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gzGfOO2akIC9",
        "outputId": "aac6f3d4-6d14-46a4-f827-08adf248cb1e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(count, bins = 100,\n",
        "         density=True, \n",
        "         histtype='bar', \n",
        "         color='b', label=None,)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.63838502e-05, 2.35517847e-04, 3.45231129e-04, 3.26799298e-04,\n",
              "        1.06787595e-03, 1.02911059e-03, 7.29812756e-04, 5.57050907e-04,\n",
              "        4.46021065e-04, 3.49034523e-04, 2.77208894e-04, 2.48683441e-04,\n",
              "        2.06553540e-04, 1.83001755e-04, 1.55646577e-04, 1.30046811e-04,\n",
              "        1.20977180e-04, 1.04300761e-04, 8.60152136e-05, 7.40198947e-05,\n",
              "        6.74370977e-05, 6.30485664e-05, 5.51492101e-05, 4.75424225e-05,\n",
              "        4.50555881e-05, 3.83265067e-05, 3.11585723e-05, 3.02808660e-05,\n",
              "        2.51609128e-05, 2.41369222e-05, 2.50146284e-05, 1.88706846e-05,\n",
              "        1.65301346e-05, 1.60912815e-05, 1.43358689e-05, 1.41895846e-05,\n",
              "        1.12638970e-05, 1.25804564e-05, 1.08250439e-05, 1.14101814e-05,\n",
              "        1.18490345e-05, 1.15564658e-05, 9.36220012e-06, 5.70509070e-06,\n",
              "        1.90169690e-06, 1.46284377e-06, 4.38853130e-07, 2.92568754e-07,\n",
              "        1.46284377e-07, 1.46284377e-07, 1.46284377e-07, 5.85137507e-07,\n",
              "        4.38853130e-07, 1.46284377e-07, 0.00000000e+00, 0.00000000e+00,\n",
              "        2.92568754e-07, 0.00000000e+00, 1.46284377e-07, 2.92568754e-07,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.46284377e-07,\n",
              "        0.00000000e+00, 1.46284377e-07, 0.00000000e+00, 0.00000000e+00,\n",
              "        2.92568754e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.46284377e-07, 0.00000000e+00, 0.00000000e+00, 2.92568754e-07,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.46284377e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 2.92568754e-07, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.46284377e-07]),\n",
              " array([   32.  ,   168.72,   305.44,   442.16,   578.88,   715.6 ,\n",
              "          852.32,   989.04,  1125.76,  1262.48,  1399.2 ,  1535.92,\n",
              "         1672.64,  1809.36,  1946.08,  2082.8 ,  2219.52,  2356.24,\n",
              "         2492.96,  2629.68,  2766.4 ,  2903.12,  3039.84,  3176.56,\n",
              "         3313.28,  3450.  ,  3586.72,  3723.44,  3860.16,  3996.88,\n",
              "         4133.6 ,  4270.32,  4407.04,  4543.76,  4680.48,  4817.2 ,\n",
              "         4953.92,  5090.64,  5227.36,  5364.08,  5500.8 ,  5637.52,\n",
              "         5774.24,  5910.96,  6047.68,  6184.4 ,  6321.12,  6457.84,\n",
              "         6594.56,  6731.28,  6868.  ,  7004.72,  7141.44,  7278.16,\n",
              "         7414.88,  7551.6 ,  7688.32,  7825.04,  7961.76,  8098.48,\n",
              "         8235.2 ,  8371.92,  8508.64,  8645.36,  8782.08,  8918.8 ,\n",
              "         9055.52,  9192.24,  9328.96,  9465.68,  9602.4 ,  9739.12,\n",
              "         9875.84, 10012.56, 10149.28, 10286.  , 10422.72, 10559.44,\n",
              "        10696.16, 10832.88, 10969.6 , 11106.32, 11243.04, 11379.76,\n",
              "        11516.48, 11653.2 , 11789.92, 11926.64, 12063.36, 12200.08,\n",
              "        12336.8 , 12473.52, 12610.24, 12746.96, 12883.68, 13020.4 ,\n",
              "        13157.12, 13293.84, 13430.56, 13567.28, 13704.  ]),\n",
              " <a list of 100 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEh7czJk55oK",
        "outputId": "663f139d-68c4-4bc9-c5c4-ab52d03e7693"
      },
      "source": [
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10405973"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxiAAeQkkIGW",
        "outputId": "ad4f1c7c-29c1-4037-9fc3-ca466c4806b1"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f074030c610>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbcdKjA3kIKL",
        "outputId": "fd26813a-4613-455c-8e91-d9456d58ea87"
      },
      "source": [
        " #Getting a baseline Naive Bayes (baseline)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_base = Pipeline([\n",
        "                       ('tfidf', TfidfVectorizer()),\n",
        "                       (\"clf\", MultinomialNB())\n",
        "                        \n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_base.fit(train_sentences, train_labels)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne8gVIGXkIOG",
        "outputId": "62bea63f-4344-466b-efa4-03dbccd97399"
      },
      "source": [
        "baseline_score = model_base.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 86.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLYiaM7vZ2Dp"
      },
      "source": [
        "baseline_pred = model_base.predict(val_sentences)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0weFZf6AXXqy"
      },
      "source": [
        " #Evaluation function for our model experiments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb4jaR3-XX7Y"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def model_accuracy_metrics(label_true, label_preds):\n",
        "  model_accuracy = accuracy_score(label_true,label_preds)\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(label_true, label_preds, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results                  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-tKSMIlXYAV",
        "outputId": "c33110b4-3d10-4b0a-b9eb-7b45b2900839"
      },
      "source": [
        "model_1_results = model_accuracy_metrics(val_labels,\n",
        "                                    baseline_pred) \n",
        "model_1_results"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8632,\n",
              " 'f1': 0.8631392707522382,\n",
              " 'precision': 0.8636896682740364,\n",
              " 'recall': 0.8632}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMfk9pq3XYGK"
      },
      "source": [
        "#Model number 2\n",
        "#LSTM_RNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6a_qk3_XYPT",
        "outputId": "484f529b-af21-4c74-8577-f10d18733147"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "model2_embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "#Now LSTM model\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = model2_embedding(x)\n",
        "x = tf.keras.layers.LSTM(128)(x)\n",
        "#x = tf.keras.layers.LSTM(64)(x)\n",
        "x= tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x= tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, output, name=\"model_2_LSTM\")\n",
        "\n",
        "#Model compile\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "#lr_schedular = tf.keras.callbacks.LearningRateScheduler((lambda epoch: 1e-3 * 10**(epoch/20))\n",
        "\n",
        "history_1 = model_2.fit(train_sentences, \n",
        "                        train_labels, \n",
        "                        epochs=3, \n",
        "                        batch_size=256,\n",
        "                        validation_data = (val_sentences, val_labels))\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "176/176 [==============================] - 19s 93ms/step - loss: 0.6790 - accuracy: 0.5565 - val_loss: 0.6659 - val_accuracy: 0.5996\n",
            "Epoch 2/3\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 0.6691 - accuracy: 0.5758 - val_loss: 0.6695 - val_accuracy: 0.5624\n",
            "Epoch 3/3\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.5844 - accuracy: 0.7042 - val_loss: 0.5988 - val_accuracy: 0.6588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79cgGb-0XYgk",
        "outputId": "9701e1f7-5638-4deb-c87f-5324d000bec3"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 231)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 231, 128)          1280000   \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,424,065\n",
            "Trainable params: 1,424,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2YStLvIXYo7"
      },
      "source": [
        "\n",
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlAk2rm3XYrw",
        "outputId": "adbca99f-a4ac-4160-c035-72d2fb773917"
      },
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RilU69yUk45h",
        "outputId": "42428463-8559-4556-a5e1-4a6354a849ec"
      },
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = model_accuracy_metrics(val_labels,\n",
        "                                    model_2_preds) \n",
        "model_2_results"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.6588,\n",
              " 'f1': 0.6273310980724969,\n",
              " 'precision': 0.7427695608484184,\n",
              " 'recall': 0.6588}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JpGwsM8k4_R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c07HMXrk5FB",
        "outputId": "06290f6a-51f8-471a-f026-3d970e41c136"
      },
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.GRU(64, return_sequences=True)(x) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x) \n",
        "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n",
        "\n",
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels)\n",
        "                             )               "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1407/1407 [==============================] - 141s 97ms/step - loss: 0.6531 - accuracy: 0.5628 - val_loss: 0.3762 - val_accuracy: 0.8338\n",
            "Epoch 2/5\n",
            "1407/1407 [==============================] - 136s 97ms/step - loss: 0.2921 - accuracy: 0.8771 - val_loss: 0.2646 - val_accuracy: 0.8892\n",
            "Epoch 3/5\n",
            "1407/1407 [==============================] - 136s 97ms/step - loss: 0.1970 - accuracy: 0.9231 - val_loss: 0.2686 - val_accuracy: 0.8920\n",
            "Epoch 4/5\n",
            "1407/1407 [==============================] - 136s 97ms/step - loss: 0.1357 - accuracy: 0.9514 - val_loss: 0.3201 - val_accuracy: 0.8876\n",
            "Epoch 5/5\n",
            "1407/1407 [==============================] - 136s 97ms/step - loss: 0.0840 - accuracy: 0.9729 - val_loss: 0.3919 - val_accuracy: 0.8776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVlXS5gXk5LT"
      },
      "source": [
        "#Make predictions on the validation dataset\n",
        "model_3_pred_probs = model_3.predict(val_sentences)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrWF1b_Ok5R7"
      },
      "source": [
        "#Round out predictions and reduce to 1-dimensional array\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f0x5-dck5X7",
        "outputId": "64244bac-2486-44dc-8327-87f5aecedc4b"
      },
      "source": [
        "# Calculate LSTM model results\n",
        "model_3_results = model_accuracy_metrics(val_labels,\n",
        "                                    model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8838,\n",
              " 'f1': 0.8837996235010214,\n",
              " 'precision': 0.883799883355801,\n",
              " 'recall': 0.8838}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaOylmZMk5cT"
      },
      "source": [
        "#TensorFlow Hub Pretrained Sentence Encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK_ytt5MoG0h"
      },
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl3QYIbpoKyN"
      },
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGlpWNmooK6P",
        "outputId": "71c9c9d6-96a2-438a-c31d-ecfac780a89f"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_4 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_4_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        " \n",
        "# Train a classifier on top of pretrained embeddings\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              )               \n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1407/1407 [==============================] - 92s 65ms/step - loss: 0.3537 - accuracy: 0.8479 - val_loss: 0.3158 - val_accuracy: 0.8638\n",
            "Epoch 2/5\n",
            "1407/1407 [==============================] - 86s 61ms/step - loss: 0.3219 - accuracy: 0.8607 - val_loss: 0.3139 - val_accuracy: 0.8658\n",
            "Epoch 3/5\n",
            "1407/1407 [==============================] - 87s 62ms/step - loss: 0.3176 - accuracy: 0.8625 - val_loss: 0.3117 - val_accuracy: 0.8648\n",
            "Epoch 4/5\n",
            "1407/1407 [==============================] - 87s 62ms/step - loss: 0.3117 - accuracy: 0.8639 - val_loss: 0.3108 - val_accuracy: 0.8640\n",
            "Epoch 5/5\n",
            "1407/1407 [==============================] - 87s 62ms/step - loss: 0.3057 - accuracy: 0.8677 - val_loss: 0.3094 - val_accuracy: 0.8652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ezZtCuSoLCP",
        "outputId": "2885918d-f983-4a66-ff55-74e8494b745a"
      },
      "source": [
        "model_4.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6mxWgZtoLIu"
      },
      "source": [
        "#Make predictions on the validation dataset\n",
        "model_4_pred_probs = model_4.predict(val_sentences)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OY8W8gYoLOl"
      },
      "source": [
        "#Round out predictions and reduce to 1-dimensional array\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq-aZrHwoLT_",
        "outputId": "8f109ec9-c4b0-47f1-920b-beb1582cd5c4"
      },
      "source": [
        "# Calculate LSTM model results\n",
        "model_4_results = model_accuracy_metrics(val_labels,\n",
        "                                    model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8652,\n",
              " 'f1': 0.8650825832103622,\n",
              " 'precision': 0.8667426762850154,\n",
              " 'recall': 0.8652}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCiMKNTipQAJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "nraLZ9WopQGV",
        "outputId": "d4aa4836-ff6a-4e46-c50d-d67182eb9538"
      },
      "source": [
        "\n",
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"Transfer_Learning\": model_4_results\n",
        "                                  })\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.8632</td>\n",
              "      <td>0.863690</td>\n",
              "      <td>0.8632</td>\n",
              "      <td>0.863139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.6588</td>\n",
              "      <td>0.742770</td>\n",
              "      <td>0.6588</td>\n",
              "      <td>0.627331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.8838</td>\n",
              "      <td>0.883800</td>\n",
              "      <td>0.8838</td>\n",
              "      <td>0.883800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Transfer_Learning</th>\n",
              "      <td>0.8652</td>\n",
              "      <td>0.866743</td>\n",
              "      <td>0.8652</td>\n",
              "      <td>0.865083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   accuracy  precision  recall        f1\n",
              "baseline             0.8632   0.863690  0.8632  0.863139\n",
              "lstm                 0.6588   0.742770  0.6588  0.627331\n",
              "gru                  0.8838   0.883800  0.8838  0.883800\n",
              "Transfer_Learning    0.8652   0.866743  0.8652  0.865083"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vSJVZpM3GXh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}